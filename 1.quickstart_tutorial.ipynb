{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMBMQeLJFz/Dtp52do32WoR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzxmHncVBiKY","executionInfo":{"status":"ok","timestamp":1724313122601,"user_tz":-480,"elapsed":33476,"user":{"displayName":"yan you","userId":"15375577698669384626"}},"outputId":"36d57c9e-e898-4e7a-dd21-b193cc5fcb10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_fT97hxBY31","executionInfo":{"status":"ok","timestamp":1724313122602,"user_tz":-480,"elapsed":4,"user":{"displayName":"yan you","userId":"15375577698669384626"}},"outputId":"7fc55be1-9b53-4be4-8e82-b20b00ed4909"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/pytorch-test/tutorials/beginner_source/basics\n"]}],"source":["%cd /content/drive/MyDrive/pytorch-test/tutorials/beginner_source/basics"]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","# from torch.utils.data import dataloader\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor"],"metadata":{"id":"Rw3z9DFJByWv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#加载数据\n","training_data = datasets.MNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","test_data = datasets.MNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")\n"],"metadata":{"id":"_JZGmP_wCYXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","\n","# 数据加载\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X,y in test_dataloader:\n","  print(f\"Shape of X [N, C, H, W]:{X.shape}\")\n","  print(f\"Shape of y :{y.shape}, {y.dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xym1P5rIDCNH","executionInfo":{"status":"ok","timestamp":1724313132975,"user_tz":-480,"elapsed":776,"user":{"displayName":"yan you","userId":"15375577698669384626"}},"outputId":"304f1424-8e55-4b80-f6a7-93c3ebf3de86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([64, 1, 28, 28])\n","Shape of y :torch.Size([64]), torch.int64\n","Shape of X [N, C, H, W]:torch.Size([16, 1, 28, 28])\n","Shape of y :torch.Size([16]), torch.int64\n"]}]},{"cell_type":"markdown","source":["\n","# **代码解析：**\n","\n","## **1. 设备选择：**\n","\n","- `device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"`：这行代码动态地确定用于训练的可用设备。它优先选择CUDA（GPU），如果可用的话，然后是MPS（苹果硅GPU），如果两者都不可用，则回退到CPU。\n","\n","## **2. 模型定义：**\n","- `class NeuralNetwork(nn.Module)`：定义一个继承自`nn.Module`的神经网络类。\n","- `self.flatten = nn.Flatten()`：将输入张量（图像）展平成一维向量。\n","- `self.linear_rule_stack = nn.Sequential(...)`：创建一个线性层和ReLU激活函数的顺序容器。\n","    - `nn.Linear(28*28, 512)`：第一个线性层接收一个28x28的输入（图像）并将其映射到512个神经元。\n","    - `nn.ReLU()`：应用ReLU激活函数以引入非线性。\n","    - `nn.Linear(512, 512)`：第二个线性层接收512维的输出并将其映射到另一个512个神经元。\n","    - `nn.ReLU()`：应用ReLU激活函数。\n","    - `nn.Linear(512, 10)`：最后一个线性层将512维的输出映射到10个神经元，代表10个可能的类别标签。\n","- `def forward(self, x)`：定义模型的正向传播。\n","    - `x = self.flatten(x)`：展平输入张量。\n","    - `logits = self.linear_rule_stack(x)`：将展平的输入通过顺序层以获得logits（未归一化的类别概率）。\n","    - `return logits`：返回logits。\n","- `model = NeuralNetwork().to(device)`：创建`NeuralNetwork`类的一个实例，并将其移动到选定的设备（CUDA、MPS或CPU）。\n","\n","### **解释：**\n","- 该代码有效地定义了一个适用于图像分类任务的神经网络架构。\n","- `flatten`层对于将2D图像数据转换成1D向量以供线性层处理至关重要。\n","- 线性层和ReLU激活函数的顺序容器允许灵活地建模输入和输出之间的非线性关系。\n","- 最后一个层输出logits，可以在进行预测之前通过softmax函数将其转换为概率。\n","- 将模型移动到选定的设备上确保了在适当的硬件上进行高效计算。\n","\n","### **关键点：**\n","- 代码结构良好，易于理解。\n","- 它为构建和训练用于图像分类的神经网络提供了一个坚实的基础。\n","- 设备的选择确保了基于可用硬件的最优性能。\n","- 使用顺序容器和激活函数允许自定义和尝试不同的架构。\n"],"metadata":{"id":"9htfD2L355kF"}},{"cell_type":"markdown","source":["在Python中，`super().__init__()` 是一个常用的语句，它用于调用父类（也称为超类或基类）的 `__init__` 方法。这通常出现在子类（也称为派生类）的构造函数（`__init__` 方法）中，目的是确保在子类中进行初始化之前，父类的初始化逻辑也被执行。\n","\n","下面是一个简单的例子来说明这一点：\n","```python\n","class ParentClass:\n","    def __init__(self):\n","        print(\"父类的初始化\")\n","class ChildClass(ParentClass):\n","    def __init__(self):\n","        super().__init__()  # 调用父类的 __init__ 方法\n","        print(\"子类的初始化\")\n","# 创建 ChildClass 的实例\n","child_instance = ChildClass()\n","```\n","\n","在这个例子中，当你创建 `ChildClass` 的一个实例时，首先会调用 `ParentClass` 的 `__init__` 方法，打印出 \"父类的初始化\"。然后，控制权返回到 `ChildClass` 的 `__init__` 方法，打印出 \"子类的初始化\"。\n","\n","使用 `super()` 是一种良好的面向对象编程实践，它有助于维护继承层次结构，并确保所有必要的初始化步骤都被执行。这在涉及多重继承的情况下特别有用，因为 `super()` 能够正确处理方法解析顺序（MRO）。\n"],"metadata":{"id":"MhmlFmNaHsWw"}},{"cell_type":"code","source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","# 定义模型\n","class NeuralNetwork(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.flatten = nn.Flatten()\n","    self.linear_rule_stack = nn.Sequential(\n","        nn.Linear(28*28, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512,10)\n","    )\n","\n","  def forward(self, x):\n","    x = self.flatten(x)\n","    logits = self.linear_rule_stack(x)\n","    return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKyy022ED_8l","executionInfo":{"status":"ok","timestamp":1724313159683,"user_tz":-480,"elapsed":2,"user":{"displayName":"yan you","userId":"15375577698669384626"}},"outputId":"d191e461-35f1-449f-d234-6e0383c62484"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_rule_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["## 优化模型参数：损失函数和优化器\n","\n","### 损失函数 (loss function)\n","\n","**`nn.CrossEntropyLoss()`** 是 PyTorch 中常用的交叉熵损失函数。它常用于多分类问题，计算预测概率分布与真实标签之间的差异。\n","\n","* **为什么使用交叉熵损失？**\n","  * **直观性:** 交叉熵衡量两个概率分布之间的差异，越小表示预测越准确。\n","  * **广泛应用:** 在神经网络中，尤其是分类问题，交叉熵损失是标准的选择。\n","\n","* **何时使用？**\n","  * 当你的输出层是一个 Softmax 层，输出的是各个类别的概率分布时，交叉熵损失非常适合。\n","  * 对于二分类问题，也可以使用二元交叉熵损失 (Binary Cross Entropy Loss)。\n","\n","### 优化器 (optimizer)\n","\n","**`torch.optim.SGD(model.parameters(), lr=1e-3)`** 使用了随机梯度下降 (Stochastic Gradient Descent, SGD) 优化器。\n","\n","* **SGD 的工作原理：**\n","  * 通过计算损失函数对模型参数的梯度，来更新参数，使得模型在参数空间中朝着损失函数减小的方向移动。\n","  * 随机梯度下降每次只用一个样本或一小批样本计算梯度，因此效率更高，但也可能导致训练过程不稳定。\n","\n","* **参数说明：**\n","  * `model.parameters()`: 获取模型中所有需要更新的参数。\n","  * `lr=1e-3`: 学习率 (learning rate) 设置为 0.001，控制每次参数更新的步长。学习率过大可能导致模型不收敛，过小则训练速度过慢。\n","\n","### 优化过程\n","\n","1. **前向传播:** 将输入数据送入模型，得到预测结果。\n","2. **计算损失:** 使用交叉熵损失函数计算预测结果与真实标签之间的差异。\n","3. **反向传播:** 计算损失函数对模型参数的梯度。\n","4. **参数更新:** 使用 SGD 优化器根据计算得到的梯度更新模型参数。\n","\n","### 进一步优化\n","\n","* **学习率调整:** 可以使用学习率调度器 (learning rate scheduler) 随着训练过程动态调整学习率，提高收敛速度。\n","* **优化器选择:** 除了 SGD，还有 Adam、RMSprop 等其他优化器，可以根据具体任务选择适合的优化器。\n","* **正则化:** 添加 L1 或 L2 正则化可以防止过拟合。\n","* **数据增强:** 对训练数据进行随机变换，增加模型的泛化能力。\n","\n","### 代码解读\n","\n","```python\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","```\n","\n","* **第一行:** 定义了一个交叉熵损失函数实例。\n","* **第二行:** 创建了一个 SGD 优化器，并指定了要优化的参数和学习率。\n","\n","### 总结\n","\n","这段代码为模型训练设置了损失函数和优化器，是深度学习模型训练中最基础的一步。通过合理选择损失函数和优化器，并结合其他优化技巧，可以有效提高模型的性能。\n","\n","\n"],"metadata":{"id":"dTF29XyQ5IRe"}},{"cell_type":"code","source":["# 优化模型参数\n","# 损失函数和优化器\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n"],"metadata":{"id":"9dD_19G4ITeE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["这段代码定义了一个名为`train`的函数，用于执行机器学习模型的训练循环。以下是每个部分的作用分解：\n","\n","# **函数参数：**\n","* `dataloader`：这是一个数据加载器对象，它提供了训练数据的批次。它按特定顺序遍历数据集，并确保高效的内存使用。\n","* `model`：这是您想要训练的机器学习模型。模型应该有一个`forward`方法，它接收输入数据并返回预测结果。\n","* `loss_fn`：这是用于测量模型预测与真实标签之间差异的损失函数。\n","* `optimizer`：这是优化器对象，用于根据计算出的损失更新模型的权重。\n","\n","# **函数体：**\n","1. **获取数据集大小：**\n","  * `size = len(dataloader.dataset)`：这行代码计算由数据加载器表示的数据集中的数据点总数。\n","2. **设置模型为训练模式：**\n","  * `model.train()`：这行代码将模型设置为训练模式。这可能会影响某些层的行为，比如在训练期间用于正则化的dropout层。\n","3. **遍历训练数据：**\n","  * `for batch, (X, y) in enumerate(dataloader)`：这个循环遍历数据加载器提供的每个批次的数据。\n","      * `batch`：这个变量表示当前的批次编号。\n","      * `(X, y)`：这将批次数据解包到两个变量中：\n","          * `X`：这表示当前批次的输入特征。\n","          * `y`：这表示当前批次的相应标签（真实值）。\n","4. **将数据移动到设备上：**\n","  * `X, y = X.to(device), y.to(device)`：这行代码假设您正在使用GPU进行训练。它将数据（特征和标签）移动到指定的设备（`device`）上，该设备可能是CPU或GPU，具体取决于您的设置。\n","5. **计算预测误差：**\n","  * `pred = model(X)`：这行代码将当前批次的特征（`X`）通过模型以获取预测结果（`pred`）。\n","  * `loss = loss_fn(pred, y)`：这行代码使用选定的损失函数（`loss_fn`）计算损失。它将模型的预测结果（`pred`）与真实标签（`y`）进行比较。\n","6. **反向传播和优化：**\n","  * `loss.backward()`：这行代码执行反向传播。它计算损失函数相对于每个模型参数（权重和偏置）的梯度。\n","  * `optimizer.step()`：这行代码根据计算出的梯度使用选定的优化器（`optimizer`）更新模型的权重。\n","  * `optimizer.zero_grad()`：这行代码将梯度重置为零，以便下一轮迭代。\n","7. **打印训练进度（可选）：**\n","  * `if batch % 100 == 0`：这检查当前批次编号是否是100的倍数（可以根据需要调整更新频率）。\n","      * `loss, current = loss.item(), (batch + 1) * len(X)`：这计算当前损失值以及到目前为止处理过的样本数量。\n","      * `print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")`：这打印当前损失、处理过的样本数量以及数据集中的总样本数量。\n","\n","这个`train`函数有效地遍历训练数据，计算损失，更新模型的权重，并提供关于训练进度的可选反馈。\n"],"metadata":{"id":"KCyWS8_25Dqr"}},{"cell_type":"markdown","source":["这里是`train`函数的详细分解，包括逐行注释：\n","```python\n","def train(dataloader, model, loss_fn, optimizer):\n","  \"\"\"\n","  这个函数使用提供的dataloader、损失函数和优化器来训练给定的模型。\n","  参数:\n","      dataloader: 一个PyTorch dataloader对象，提供训练数据的批次。\n","      model: 要训练的机器学习模型。\n","      loss_fn: 用于测量预测值与真实标签之间差异的损失函数。\n","      optimizer: 根据计算出的损失更新模型权重的优化器。\n","  \"\"\"  \n","  # 获取数据集中的总样本数\n","  size = len(dataloader.dataset)\n","  # 将模型设置为训练模式（影响某些层的行为）\n","  model.train()\n","  # 遍历dataloader提供的每个批次的数据\n","  for batch, (X, y) in enumerate(dataloader):\n","    # 将数据移动到选择的设备（CPU、GPU或MPS）\n","    X, y = X.to(device), y.to(device)\n","    # 计算预测误差（损失）\n","    pred = model(X)  # 前向传播：从模型获取预测\n","    loss = loss_fn(pred, y)  # 使用选择的损失函数计算损失\n","    # 反向传播：为参数更新计算梯度\n","    loss.backward()\n","    # 使用优化器根据梯度更新模型权重\n","    optimizer.step()\n","    # 清除梯度，为下一轮迭代做准备（避免梯度累积）\n","    optimizer.zero_grad()\n","    # 每100个批次打印一次训练进度（可选）\n","    if batch % 100 == 0:\n","      loss_val = loss.item()  # 提取实际的损失值（标量）\n","      current = (batch + 1) * len(X)  # 计算到目前为止处理的样本数\n","      print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n","```\n","# **解释：**\n","1. **函数定义：**\n","   - `def train(dataloader, model, loss_fn, optimizer)`：定义了一个名为`train`的函数，它接受四个参数：\n","      - `dataloader`：一个PyTorch dataloader对象。\n","      - `model`：要训练的机器学习模型。\n","      - `loss_fn`：用于计算误差的损失函数。\n","      - `optimizer`：用于根据计算出的损失更新模型权重的优化器。\n","2. **获取数据集大小：**\n","   - `size = len(dataloader.dataset)`：计算由dataloader表示的数据集中的数据点总数。这在训练期间用于跟踪进度。\n","3. **设置模型为训练模式：**\n","   - `model.train()`：将模型设置为训练模式。这可能会影响某些层的行为，例如dropout层，这些层在训练期间用于正则化。\n","4. **遍历训练数据：**\n","   - `for batch, (X, y) in enumerate(dataloader)`：这个循环遍历dataloader提供的每个批次的数据。\n","      - `batch`：这个变量表示当前批次的编号（从0开始）。\n","      - `(X, y)`：这解包了批次数据到两个变量中：\n","          - `X`：这表示当前批次的输入特征。\n","          - `y`：这表示当前批次的相应标签（真实值）。\n","5. **将数据移动到设备：**\n","   - `X, y = X.to(device), y.to(device)`：假设您使用GPU进行训练，这行代码将数据（特征和标签）移动到指定的设备（`device`）上，这可能是CPU或GPU，具体取决于您的设置。\n","6. **计算预测误差（损失）：**\n","   - `pred = model(X)`：这行代码将当前批次的特征（`X`）通过模型以获取预测（`pred`）。\n","   - `loss = loss_fn(pred, y)`：这行代码使用选定的损失函数（`loss_fn`）计算损失。它比较模型的预测（`pred`）与真实标签（`y`）。\n","7. **反向传播和优化：**\n","   - `loss.backward()`：这行代码执行反向传播。它计算损失函数相对于每个模型参数（权重和偏置）的梯度。\n","   - `optimizer.step()`：这行代码根据计算出的梯度使用选定的优化器（`optimizer`）更新模型的权重。\n","   - `optimizer.zero_grad()`：这行代码重置梯度，为下一次迭代做准备，避免梯度在迭代过程中累积。\n","\n","这段代码描述了在训练循环中如何使用反向传播来计算梯度，并使用优化器来更新模型参数，从而使得模型更加准确。在执行`optimizer.step()`之前，通常需要先执行`optimizer.zero_grad()`来确保梯度在每次迭代开始时被清零，这样可以防止梯度在多个批次之间累积，从而影响模型的训练过程。\n"],"metadata":{"id":"cHPvAgg9-Egs"}},{"cell_type":"code","source":["def train(dataloader, model, loss_fn, optimizer):\n","  \"\"\"\n","  This function trains the given model using the provided dataloader, loss function, and optimizer.\n","\n","  Args:\n","      dataloader: A PyTorch dataloader object that provides batches of training data.\n","      model: The machine learning model to be trained.\n","      loss_fn: The loss function used to measure the difference between predictions and true labels.\n","      optimizer: The optimizer used to update the model's weights based on the calculated loss.\n","  \"\"\"\n","\n","  # Get the total number of samples in the dataset\n","  size = len(dataloader.dataset)\n","\n","  # Set the model to training mode (affects behavior of certain layers)\n","  model.train()\n","\n","  # Iterate over each batch of data provided by the dataloader\n","  for batch, (X, y) in enumerate(dataloader):\n","\n","    # Move data to the chosen device (CPU, GPU, or MPS)\n","    X, y = X.to(device), y.to(device)\n","\n","    # Calculate the prediction error (loss)\n","    pred = model(X)  # Forward pass: Get predictions from the model\n","    loss = loss_fn(pred, y)  # Calculate loss using the chosen loss function\n","\n","    # Backpropagation: Calculate gradients for parameter updates\n","    loss.backward()\n","\n","    # Update model weights based on gradients using the optimizer\n","    optimizer.step()\n","\n","    # Clear gradients for the next iteration (avoids accumulating gradients)\n","    optimizer.zero_grad()\n","\n","    # Print training progress every 100 batches (optional)\n","    if batch % 100 == 0:\n","      loss_val = loss.item()  # Extract the actual loss value (scalar)\n","      current = (batch + 1) * len(X)  # Calculate the number of samples processed so far\n","      print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n"],"metadata":{"id":"n2Ka3qiUKwuP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["当然！以下是`test`函数的详细分解，包括逐行注释：\n","```python\n","def test(dataloader, model, loss_fn):\n","  \"\"\"\n","  这个函数在给定的dataloader上评估模型的性能。\n","  参数:\n","      dataloader: 一个PyTorch dataloader对象，提供测试数据的批次。\n","      model: 训练好的机器学习模型。\n","      loss_fn: 用于评估时测量预测值与真实标签之间差异的损失函数。\n","  \"\"\"\n","  # 获取数据集中的总样本数\n","  size = len(dataloader.dataset)\n","  # 获取dataloader中的批次数\n","  num_batches = len(dataloader)\n","  # 将模型设置为评估模式（禁用dropout和其他训练特定的行为）\n","  model.eval()\n","  # 初始化用于跟踪测试损失和准确性的变量\n","  test_loss = 0  # 用于累计总测试损失\n","  correct = 0    # 用于累计正确预测的数量\n","  # 在评估期间禁用梯度计算以提高性能\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","      # 将数据移动到选择的设备（CPU、GPU或MPS）\n","      X, y = X.to(device), y.to(device)\n","      # 获取当前批次的模型预测\n","      pred = model(X)\n","      # 使用选定的损失函数计算批次的损失\n","      batch_loss = loss_fn(pred, y).item()  # 提取实际的损失值（标量）\n","      # 更新总测试损失\n","      test_loss += batch_loss\n","      # 计算当前批次中正确的预测数量\n","      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","  # 计算平均测试损失\n","  test_loss /= num_batches\n","  # 计算准确率\n","  correct /= size\n","  # 打印测试结果\n","  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","```\n","# **解释：**\n","1. **函数定义：**\n","   - `def test(dataloader, model, loss_fn)`：定义了一个名为`test`的函数，它接受三个参数：\n","      - `dataloader`：一个包含测试数据的PyTorch dataloader对象。\n","      - `model`：已经训练好的机器学习模型。\n","      - `loss_fn`：用于评估时测量预测值与真实标签之间差异的损失函数。\n","2. **获取数据集大小和批次数：**\n","   - `size = len(dataloader.dataset)`：类似于`train`函数，这行代码计算由dataloader表示的数据集中的数据点总数。\n","   - `num_batches = len(dataloader)`：这计算了dataloader中的批次数，这对于计算所有批次的平均损失很有用。\n","3. **设置模型为评估模式：**\n","   - `model.eval()`：将模型设置为评估模式。这可能会禁用某些层，如在训练期间用于正则化的dropout层，这可能会在评估期间提高性能。\n","4. **初始化变量：**\n","   - `test_loss = 0`：初始化一个变量来累计所有批次的总测试损失。\n","   - `correct = 0`：初始化一个变量来累计正确预测的数量。\n","5. **禁用梯度计算：**\n","   - `with torch.no_grad()`：这个块确保在评估期间不计算梯度。梯度计算计算量较大，在评估时不需要。\n","6. **遍历测试数据：**\n","   - `for X, y in dataloader`：这个循环遍历测试dataloader中的每个批次的数据，类似于训练循环。\n","7. **移动数据到设备：**\n","   - `X, y = X.to(device), y.to(device)`：像以前一样，这行代码将数据（特征和标签）移动到选择的设备。\n","8. **获取预测：**\n","   - `pred = model(X)`：将当前批次的特征（`X`）通过模型以获得预测（`pred`）。\n","9. **计算批次损失：**\n","   - `batch_loss = loss_fn(pred, y).item()`：使用损失函数计算当前批次的损失，并提取实际的损失值（标量）。\n","10. **更新总损失和正确预测：**\n","   - `test_loss += batch_loss`：将当前批次的损失加到累计总测试损失中。\n","   - `correct += (pred.argmax(1) == y).type(torch.float).sum().item()`：计算当前批次中正确的预测数量。这行代码首先使用`argmax(1)`找到`pred`中每个样本的最大概率对应的类别索引，然后使用`== y`进行比较，确保预测与真实标签匹配。`type(torch.float)`将比较结果转换为浮点数类型，因为`sum()`方法要求输入为浮点数。最后，`sum().item()`将张量中的元素求和，并返回一个标量值。\n","\n","这个函数在给定的测试数据集上评估模型的性能，计算总的测试损失，并跟踪正确的预测数量，以计算准确率。\n"],"metadata":{"id":"R4T9sKlx_Btu"}},{"cell_type":"code","source":["def test(dataloader, model, loss_fn):\n","  \"\"\"\n","  This function evaluates the model's performance on the given dataloader.\n","\n","  Args:\n","      dataloader: A PyTorch dataloader object that provides batches of test data.\n","      model: The trained machine learning model.\n","      loss_fn: The loss function used to measure the difference between predictions and true labels.\n","  \"\"\"\n","\n","  # Get the total number of samples in the dataset\n","  size = len(dataloader.dataset)\n","\n","  # Get the number of batches in the dataloader\n","  num_batches = len(dataloader)\n","\n","  # Set the model to evaluation mode (disables dropout and other training-specific behaviors)\n","  model.eval()\n","\n","  # Initialize variables for tracking test loss and accuracy\n","  test_loss = 0  # Accumulator for total test loss\n","  correct = 0    # Accumulator for number of correct predictions\n","\n","  # Disable gradient calculation for better performance during evaluation\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","\n","      # Move data to the chosen device (CPU, GPU, or MPS)\n","      X, y = X.to(device), y.to(device)\n","\n","      # Get model predictions for the current batch\n","      pred = model(X)\n","\n","      # Calculate batch loss using the chosen loss function\n","      batch_loss = loss_fn(pred, y).item()  # Extract the actual loss value (scalar)\n","\n","      # Update the total test loss\n","      test_loss += batch_loss\n","\n","      # Calculate the number of correct predictions in the current batch\n","      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","  # Calculate average test loss\n","  test_loss /= num_batches\n","\n","  # Calculate accuracy\n","  correct /= size\n","\n","  # Print test results\n","  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"metadata":{"id":"soIApmwJOWBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","\n","for t in range(epochs):\n","  print(f\"Epoch {t+1}\\n----------------------------\")\n","  train(train_dataloader, model, loss_fn, optimizer)\n","  test(test_dataloader, model, loss_fn)\n","\n","print(\"Done!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nTopzmnAhdR","executionInfo":{"status":"ok","timestamp":1724313232244,"user_tz":-480,"elapsed":48826,"user":{"displayName":"yan you","userId":"15375577698669384626"}},"outputId":"69e35ba0-c63b-4732-9dfe-17f8b327b189"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","----------------------------\n","loss: 2.304570  [   64/60000]\n","loss: 2.302738  [ 6464/60000]\n","loss: 2.284112  [12864/60000]\n","loss: 2.286226  [19264/60000]\n","loss: 2.276767  [25664/60000]\n","loss: 2.284557  [32064/60000]\n","loss: 2.266635  [38464/60000]\n","loss: 2.274374  [44864/60000]\n","loss: 2.260965  [51264/60000]\n","loss: 2.245908  [57664/60000]\n","Test Error: \n"," Accuracy: 29.8%, Avg loss: 2.251917 \n","\n","Epoch 2\n","----------------------------\n","loss: 2.257498  [   64/60000]\n","loss: 2.250208  [ 6464/60000]\n","loss: 2.245125  [12864/60000]\n","loss: 2.226367  [19264/60000]\n","loss: 2.224510  [25664/60000]\n","loss: 2.229824  [32064/60000]\n","loss: 2.202370  [38464/60000]\n","loss: 2.227397  [44864/60000]\n","loss: 2.197726  [51264/60000]\n","loss: 2.178297  [57664/60000]\n","Test Error: \n"," Accuracy: 61.4%, Avg loss: 2.183261 \n","\n","Epoch 3\n","----------------------------\n","loss: 2.189927  [   64/60000]\n","loss: 2.173557  [ 6464/60000]\n","loss: 2.184169  [12864/60000]\n","loss: 2.135005  [19264/60000]\n","loss: 2.142450  [25664/60000]\n","loss: 2.142101  [32064/60000]\n","loss: 2.098906  [38464/60000]\n","loss: 2.146448  [44864/60000]\n","loss: 2.092133  [51264/60000]\n","loss: 2.063334  [57664/60000]\n","Test Error: \n"," Accuracy: 69.9%, Avg loss: 2.065600 \n","\n","Epoch 4\n","----------------------------\n","loss: 2.074654  [   64/60000]\n","loss: 2.041520  [ 6464/60000]\n","loss: 2.073099  [12864/60000]\n","loss: 1.979363  [19264/60000]\n","loss: 1.996344  [25664/60000]\n","loss: 1.986590  [32064/60000]\n","loss: 1.919573  [38464/60000]\n","loss: 1.999838  [44864/60000]\n","loss: 1.907662  [51264/60000]\n","loss: 1.863665  [57664/60000]\n","Test Error: \n"," Accuracy: 72.8%, Avg loss: 1.860514 \n","\n","Epoch 5\n","----------------------------\n","loss: 1.876016  [   64/60000]\n","loss: 1.815842  [ 6464/60000]\n","loss: 1.873214  [12864/60000]\n","loss: 1.725550  [19264/60000]\n","loss: 1.747097  [25664/60000]\n","loss: 1.726573  [32064/60000]\n","loss: 1.635579  [38464/60000]\n","loss: 1.760517  [44864/60000]\n","loss: 1.626405  [51264/60000]\n","loss: 1.568964  [57664/60000]\n","Test Error: \n"," Accuracy: 74.6%, Avg loss: 1.556170 \n","\n","Done!\n"]}]},{"cell_type":"code","source":["# save model and loading model\n","torch.save(model.state_dict(), \"model/mnist-model.pth\")\n","print(\"Save Pytorch Model State to mnist-model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aap7r1I4BHqX","executionInfo":{"status":"ok","timestamp":1724313237455,"user_tz":-480,"elapsed":890,"user":{"displayName":"yan you","userId":"15375577698669384626"}},"outputId":"c4f79d48-c026-4777-d2b9-8b318513d4b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Save Pytorch Model State to mnist-model.pth\n"]}]},{"cell_type":"code","source":["model = NeuralNetwork().to(device)\n","model.load_state_dict(torch.load(\"./model/mnist-model.pth\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwZjU-KMBY7s","executionInfo":{"status":"ok","timestamp":1724313238897,"user_tz":-480,"elapsed":2,"user":{"displayName":"yan you","userId":"15375577698669384626"}},"outputId":"e61da36b-0645-4790-92ca-8dc31ce0b9eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["classes = [\n","    \"0\",\n","    \"1\",\n","    \"2\",\n","    \"3\",\n","    \"4\",\n","    \"5\",\n","    \"6\",\n","    \"7\",\n","    \"8\",\n","    \"9\",\n","]\n","\n","model.eval()\n","x, y = test_data[0][0], test_data[0][1]\n","with torch.no_grad():\n","    x = x.to(device)\n","    pred = model(x)\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6lKgnZmUCJy4","executionInfo":{"status":"ok","timestamp":1724313248938,"user_tz":-480,"elapsed":2,"user":{"displayName":"yan you","userId":"15375577698669384626"}},"outputId":"f4171d09-a588-4102-acd8-6fc6920613f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: \"7\", Actual: \"7\"\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uOTDlH8UEKHt"},"execution_count":null,"outputs":[]}]}